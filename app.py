import cv2
import mediapipe as mp
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# ğŸ¨ MediaPipe
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=2)
mp_draw = mp.solutions.drawing_utils

# ğŸ¨ Ù¾Ù„Øª Ø±Ù†Ú¯ÛŒ
PALETTE = [
    ((0, 0, 255), (10, 10, 90, 60)),       # Ù‚Ø±Ù…Ø²
    ((0, 255, 0), (110, 10, 190, 60)),     # Ø³Ø¨Ø²
    ((255, 0, 0), (210, 10, 290, 60)),     # Ø¢Ø¨ÛŒ
    ((0, 255, 255), (310, 10, 390, 60)),   # Ø²Ø±Ø¯
    ((255, 255, 255), (410, 10, 490, 60))  # Ø³ÙÛŒØ¯
]

# âœ‹ Ú†Ú© Ú©Ø±Ø¯Ù† Ø§Ù†Ú¯Ø´Øªâ€ŒÙ‡Ø§
def fingers_up(hand_landmarks):
    tips_ids = [4, 8, 12, 16, 20]
    fingers = []

    # Ø´Ø³Øª
    if hand_landmarks.landmark[4].x < hand_landmarks.landmark[3].x:
        fingers.append(1)
    else:
        fingers.append(0)

    # Ø¨Ù‚ÛŒÙ‡ Ø§Ù†Ú¯Ø´Øªâ€ŒÙ‡Ø§
    for tip_id in tips_ids[1:]:
        if hand_landmarks.landmark[tip_id].y < hand_landmarks.landmark[tip_id - 2].y:
            fingers.append(1)
        else:
            fingers.append(0)
    return fingers


# ğŸ¥ Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯Ø¦Ùˆ
class HandPainter(VideoTransformerBase):
    def __init__(self):
        self.canvas = np.zeros((720, 1280, 3), dtype=np.uint8)
        self.color = (0, 0, 255)
        self.prev_point = None

    def transform(self, frame):
        frame = frame.to_ndarray(format="bgr24")
        frame = cv2.flip(frame, 1)
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)

        # Ú©Ø´ÛŒØ¯Ù† Ù¾Ù„Øª Ø±Ù†Ú¯ÛŒ
        for color_box, (x1, y1, x2, y2) in PALETTE:
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)
            cv2.rectangle(frame, (x1+2, y1+2), (x2-2, y2-2), color_box, -1)

        if results.multi_hand_landmarks:
            for handLms in results.multi_hand_landmarks:
                h, w, _ = frame.shape
                lm = handLms.landmark
                Cx = int(lm[8].x * w)   # Ù†ÙˆÚ© Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡
                Cy = int(lm[8].y * h)

                fingers = fingers_up(handLms)

                # Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ù†Ú¯Ø´Øª
                cv2.circle(frame, (Cx, Cy), 10, (0, 0, 255), -1)

                # Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ù†Ú¯
                if Cy < 70:
                    for color_box, (x1, y1, x2, y2) in PALETTE:
                        if x1 < Cx < x2 and y1 < Cy < y2:
                            self.color = color_box

                # Ù…Ø¯ Ù†Ù‚Ø§Ø´ÛŒ (ÙÙ‚Ø· Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ Ø¨Ø§Ù„Ø§)
                elif fingers[1] == 1 and fingers[2] == 0:
                    if self.prev_point is not None:
                        cv2.line(self.canvas, self.prev_point, (Cx, Cy), self.color, 5)
                    self.prev_point = (Cx, Cy)

                # Ù…Ø¯ Ù¾Ø§Ú©â€ŒÚ©Ù† (Ø§Ø´Ø§Ø±Ù‡ + ÙˆØ³Ø· Ø¨Ø§Ù„Ø§)
                elif fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 0 and fingers[4] == 0:
                    if self.prev_point is not None:
                        cv2.line(self.canvas, self.prev_point, (Cx, Cy), (0, 0, 0), 50)
                    self.prev_point = (Cx, Cy)
                else:
                    self.prev_point = None

                mp_draw.draw_landmarks(frame, handLms, mp_hands.HAND_CONNECTIONS)
        else:
            self.prev_point = None

        combo = cv2.add(frame, self.canvas)
        return combo

    def save_canvas(self, path="drawing.png"):
        white_bg = np.ones_like(self.canvas) * 255
        mask = np.any(self.canvas != 0, axis=2)
        white_bg[mask] = self.canvas[mask]
        cv2.imwrite(path, white_bg)
        return path


# ğŸŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit
st.title("ğŸ¨ Hand Gesture Painter (AI Painter)")
st.markdown("Ø¨Ø§ Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ Ù†Ù‚Ø§Ø´ÛŒ Ø¨Ú©Ø´ØŒ Ø¨Ø§ Ø§Ø´Ø§Ø±Ù‡+ÙˆØ³Ø· Ù¾Ø§Ú© Ú©Ù†ØŒ Ø¨Ø§Ù„Ø§ÛŒ ØµÙØ­Ù‡ Ø±Ù†Ú¯ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†.")

webrtc_ctx = webrtc_streamer(
    key="painter",
    video_transformer_factory=HandPainter,
    media_stream_constraints={"video": True, "audio": False},
)

if webrtc_ctx.video_transformer:
    if st.button("ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø§Ø´ÛŒ"):
        path = webrtc_ctx.video_transformer.save_canvas()
        st.image(path, caption="Your Drawing", use_column_width=True)
